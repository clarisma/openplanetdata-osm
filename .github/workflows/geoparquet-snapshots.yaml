name: Build & Publish Geoparquet Snapshots

on:
  workflow_dispatch:
  workflow_run:
    workflows: ["Build & Publish CRCP Snapshots"]
    types: [completed]

env:
  REMOTE_NAME: openplanetdata-r2
  OHSOME_JAR_PATH: ohsome-planet/ohsome-planet-cli/target/ohsome-planet.jar

jobs:
  geoparquet:
    runs-on: openplanetdata-cortex

    outputs:
      tag: ${{ steps.date.outputs.tag }}

    steps:
      - name: Show runner architecture
        run: echo "arch = ${{ runner.arch }}"

      - name: Set date tag
        id: date
        run: echo "tag=$(date '+%Y%m%d')" >>"$GITHUB_OUTPUT"

      - name: Install system dependencies
        shell: bash
        run: |
          need_install() { ! command -v "$1" &>/dev/null; }
          pkgs=()
          need_install jq    && pkgs+=(jq)
          need_install unzip && pkgs+=(unzip)
          if [ ${#pkgs[@]} -gt 0 ]; then
            sudo dnf -y install "${pkgs[@]}"
          fi

      - uses: actions/setup-java@v4
        with:
          distribution: temurin
          java-version: 21

      - uses: actions/setup-python@v5
        with:
          cache: pip

      - name: Python deps for merge
        run: pip install --quiet duckdb

      - name: Get latest ohsome-planet release tag
        id: get_tag
        run: |
          TAG=$(curl -s https://api.github.com/repos/GIScience/ohsome-planet/releases/latest | jq -r .tag_name)
          echo "tag=$TAG" >>"$GITHUB_OUTPUT"
      

      - name: Checkout ohsome-planet
        uses: actions/checkout@v4
        with:
          repository: GIScience/ohsome-planet
          ref: ${{ steps.get_tag.outputs.tag }}
          path: ohsome-planet
          submodules: recursive
      
      - name: Cache ohsome-planet JAR
        uses: actions/cache@v3
        id: jar-cache
        with:
          path: ${{ env.OHSOME_JAR_PATH }}
          key: ${{ runner.os }}-ohsome-planet-${{ steps.get_tag.outputs.tag }}

      - name: Build ohsome-planet JAR
        if: steps.jar-cache.outputs.cache-hit != 'true'
        run: |
          cd ohsome-planet
          ./mvnw -q clean package -DskipTests
          find . -name "*.jar" -type f

      - name: Configure rclone
        env:
          RCLONE_CONFIG_DATA: ${{ secrets.RCLONE_CONFIG_DATA }}
        run: |
          mkdir -p ~/.config/rclone
          printf '%s' "$RCLONE_CONFIG_DATA" > ~/.config/rclone/rclone.conf
          command -v rclone >/dev/null || curl https://rclone.org/install.sh | sudo bash

      - name: Download latest published PBF
        run: |
          rclone copy \
            --http-url https://download.openplanetdata.com :http:osm/planet/pbf/planet-latest.osm.pbf . \
            --multi-thread-cutoff 0 --multi-thread-streams 128 --multi-thread-chunk-size 512M \
            --transfers 1 --progress
          mv planet-latest.osm.pbf "planet-${{ steps.date.outputs.tag }}.osm.pbf"

      - name: Build GeoParquet with ohsome-planet from PBF
        env:
          TAG: ${{ steps.date.outputs.tag }}
        run: |
          PBF="planet-${TAG}.osm.pbf"
          OUT_DIR="ohsome-${TAG}"
          time java -Xms32g -Xmx42g -jar "${{ env.OHSOME_JAR_PATH }}" contributions \
               --pbf "$PBF" --output "$OUT_DIR" --overwrite
          
          # list everything just produced
          echo "::group::Produced files"
          find "$OUT_DIR" -print | sort
          echo "::endgroup::"

          # merge "latest" partitions to single legacy file
          time python3 - <<'PY'
          import duckdb, os, glob
          tag = os.environ["TAG"]
          glob_pat = f"ohsome-{tag}/contributions/latest/*.parquet"
          duckdb.sql(
              f"COPY (FROM parquet_scan('{glob_pat}') ORDER BY bbox.xmin, bbox.ymin, bbox.xmax, bbox.ymax) "
              f"TO 'planet-{tag}.osm.parquet' "
              " (FORMAT PARQUET, COMPRESSION ZSTD, COMPRESSION_LEVEL 20, PARQUET_VERSION v2);"
          )
          PY

      - name: Generate checksums & metadata
        env:
          TAG: ${{ steps.date.outputs.tag }}
        run: |
          f="planet-${TAG}.osm.parquet"
          sha256sum "$f" >"$f.sha256"
          stat -c '%s %W %Z' "$f" | \
            awk '{print "{\"created\":"($2==0?$3:$2)",\"size\":"$1"}"}' >"$f.metadata"

      - name: Upload GeoParquet files to R2
        env:
          RCLONE_CONFIG_DATA: ${{ secrets.RCLONE_CONFIG_DATA }}
        run: |
          d=${{ steps.date.outputs.tag }}
          rclone copyto "planet-$d.osm.parquet"          "$REMOTE_NAME:openplanetdata/osm/planet/geoparquet/planet-latest.osm.parquet"
          rclone copyto "planet-$d.osm.parquet.metadata" "$REMOTE_NAME:openplanetdata/osm/planet/geoparquet/planet-latest.osm.parquet.metadata"
          rclone copyto "planet-$d.osm.parquet.sha256"   "$REMOTE_NAME:openplanetdata/osm/planet/geoparquet/planet-latest.osm.parquet.sha256"

      - name: Cleanup downloaded and generated files
        if: always()
        run: |
          rm -f planet-*.osm.pbf planet-*.osm.parquet planet-*.osm.parquet.{sha256,metadata}
          rm -rf ohsome-*
          rm -rf ohsome-planet
          find . -name "*.jar" -delete
          find /tmp -name "tmp.*" -user "$USER" -delete 2>/dev/null || true
